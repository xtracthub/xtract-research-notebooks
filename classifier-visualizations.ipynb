{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b1e907",
   "metadata": {},
   "source": [
    "# Importing the classifier pickle\n",
    "NOTE: pickle must contain the trained __classifier__, not just the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08590c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "\n",
    "from sklearn import tree\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ------ Fill this in to specify which pickle should be opened ------\n",
    "# --- NOTE: should include full path and filename but NO extension ---\n",
    "file = \"stored_models/trained_classifiers/dtc/dtc-head-16-cord_multilabel_gt_corrected.csv-2022-04-12-03.40.54\"\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "byte_count = int(file.split(\"/\")[-1].split(\"-\")[2])\n",
    "\n",
    "classifier_path = f\"{file}.pkl\"\n",
    "info_metrics_path = f\"{file}-info-{byte_count}Bytes.json\"\n",
    "\n",
    "info_metrics = json.load(open(info_metrics_path))\n",
    "\n",
    "# os.chdir('../XtractPredictor/')\n",
    "classifier = pickle.load(open(classifier_path, \"rb\"))\n",
    "# os.chdir('../xtract-research-notebooks/')\n",
    "\n",
    "for key in info_metrics.keys():\n",
    "    print(key)\n",
    "    print(f'\\t{info_metrics[key]}')\n",
    "\n",
    "precision = info_metrics['Model precision']\n",
    "recall = info_metrics['Model recall']\n",
    "print(f'F1-Score\\n\\t{2*precision*recall/(precision+recall)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cfbce",
   "metadata": {},
   "source": [
    "## Decision tree visualization\n",
    "Acceptable classifiers:\n",
    "- Decision tree classifier (dtc)\n",
    "- Single-tree extra tree classifier (t_etc)\n",
    "\n",
    "NOTE: If decision tree has too high of a maximum depth, this visualization will be illegible. I recommend setting max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49770e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 25))\n",
    "_ = tree.plot_tree(classifier.model,\n",
    "                   filled=True)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "label_legend = \"\"\n",
    "for label in classifier.unique_labels:\n",
    "    label_legend += (label + \"\\n\")\n",
    "fig.text(0.13, 0.7, label_legend[:-1], fontsize=25, bbox=props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f89b35",
   "metadata": {},
   "source": [
    "## HeadByte heatmap visualization\n",
    "*Acceptable classifiers: any*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.model.predict(classifier.X_test)\n",
    "\n",
    "# Building a dictionary of the predicted (multi)labels and their corresponding binary lists\n",
    "\n",
    "unique_rows = np.unique(y_pred, axis=0)\n",
    "unique_dict = {}\n",
    "for unique_row in unique_rows:\n",
    "    labels = []\n",
    "    for pair in zip(unique_row, classifier.unique_labels):\n",
    "        if pair[0]:\n",
    "            labels.append(pair[1])\n",
    "    if len(labels) == 0:\n",
    "        labels.append(\"unknown\")\n",
    "    unique_dict[\", \".join(labels)] = unique_row\n",
    "    \n",
    "# Building a dictionary of all the feature info for each predicted label\n",
    "\n",
    "large_dict = {}\n",
    "for key in unique_dict.keys():\n",
    "    large_dict[key] = []\n",
    "\n",
    "for i in range(len(classifier.X_test)):\n",
    "    for key in unique_dict.keys():\n",
    "        if np.all(y_pred[i]==unique_dict[key]):\n",
    "            large_dict[key].append(classifier.X_test[i].tolist())\n",
    "            break\n",
    "\n",
    "sample_counts = \"Predicted sample counts\\n\\n\"\n",
    "for key in large_dict.keys():\n",
    "    sample_counts += key + \" : \" + str(len(large_dict[key])) + \"\\n\"\n",
    "\n",
    "print(\"The labels and their binarized lists:\")\n",
    "for key in unique_dict.keys():\n",
    "    print(key)\n",
    "    print(unique_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc902821",
   "metadata": {},
   "source": [
    "### Average value heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the features for each bit\n",
    "\n",
    "avgs = []\n",
    "for key in large_dict.keys():\n",
    "    lst = large_dict[key]\n",
    "    lst = [list(x) for x in zip(*lst)]\n",
    "    lst = [stats.mean(x) for x in lst]\n",
    "    avgs.append(lst)\n",
    "    \n",
    "# UNCOMMENT to fill in empty labels in case you run on a limited range of samples\n",
    "\n",
    "# for i in range(len(avgs)):\n",
    "#     if (len(avgs[i])==0):\n",
    "#         avgs[i] = [0.0] * byte_count\n",
    "\n",
    "# Creating the plot\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Label y axis side with the class name\n",
    "\n",
    "y1_axis_labels = large_dict.keys()\n",
    "ax1.set_yticks(np.arange(len(y1_axis_labels)), labels=y1_axis_labels)\n",
    "\n",
    "# Plot the heatmap set good x-axis ticks\n",
    "\n",
    "fig.set_size_inches((2*byte_count)/10, 10.5) # UNCOMMENT FOR LARGER BYTECOUNTS\n",
    "plt.imshow(np.array(avgs))\n",
    "plt.xticks(ticks=[i for i in range(byte_count)], labels=[i+1 for i in range(byte_count)])\n",
    "\n",
    "# Adding title and sample count legend\n",
    "\n",
    "ax1.set_title(\"Average scalar value of n-th head byte for each predicted multilabel\")\n",
    "plt.tight_layout()\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(byte_count, -0.25, sample_counts[:-1], fontsize=10,\n",
    "         verticalalignment='top', bbox=props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be416262",
   "metadata": {},
   "source": [
    "### Standard deviation value heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea20a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding the standard deviation for each bit\n",
    "\n",
    "stdevs = []\n",
    "y_axis_labels = []\n",
    "for key in large_dict.keys():\n",
    "    lst = large_dict[key]\n",
    "    lst = [list(x) for x in zip(*lst)]\n",
    "    if (len(lst[0])>1):\n",
    "        lst = [stats.stdev(x) for x in lst]\n",
    "        stdevs.append(lst)\n",
    "        y_axis_labels.append(key)\n",
    "    \n",
    "# UNCOMMENT to fill in empty labels in case you run on a limited range of samples\n",
    "\n",
    "# for i in range(len(stdevs)):\n",
    "#     if (len(stdevs[i])==0):\n",
    "#         stdevs[i] = [0.0] * byte_count\n",
    "\n",
    "# Creating the plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(np.array(stdevs))\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "\n",
    "ax.set_yticks(np.arange(len(y_axis_labels)), labels=y_axis_labels)\n",
    "\n",
    "# Plot the heatmap set good x-axis ticks\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5) # UNCOMMENT FOR LARGER BYTECOUNTS\n",
    "plt.imshow(np.array(stdevs))\n",
    "plt.xticks(ticks=[i for i in range(byte_count)], labels=[i+1 for i in range(byte_count)])\n",
    "\n",
    "# Adding title and sample count legend\n",
    "\n",
    "ax1.set_title(\"Standard deviation of scalar values of n-th head byte\")\n",
    "plt.tight_layout()\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(byte_count, -0.25, sample_counts[:-1], fontsize=10,\n",
    "         verticalalignment='top', bbox=props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071c819",
   "metadata": {},
   "source": [
    "## Multilabel Confusion Matrices\n",
    "*Acceptable classifiers: any*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f802575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    axes.set_ylabel('True label')\n",
    "    axes.set_xlabel('Predicted label')\n",
    "    axes.set_title(\"Confusion Matrix for the class - \" + class_label)\n",
    "\n",
    "y_pred = classifier.model.predict(classifier.X_test)\n",
    "    \n",
    "# Some customizable values here, first two values should multiply to at least label count\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 7))\n",
    "    \n",
    "multilabel_confusion_matrix = multilabel_confusion_matrix(y_pred, classifier.Y_test)\n",
    "multilabel_labels = classifier.unique_labels\n",
    "\n",
    "for axes, cfs_matrix, label in zip(ax.flatten(), multilabel_confusion_matrix, multilabel_labels):\n",
    "    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = classifier.model.predict(classifier.X_test)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if (not (np.array_equal(y_pred[i], classifier.Y_test[i]))):\n",
    "        print(f'{i}: {y_pred[i]}, {classifier.Y_test[i]}')\n",
    "#     print(y_pred[i])\n",
    "#     print(classifier.Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a86c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_pred, classifier.Y_test, average='samples'))\n",
    "print(recall_score(y_pred, classifier.Y_test, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "byte_count = int(file.split(\"/\")[-1].split(\"-\")[2])\n",
    "\n",
    "classifier_path = f\"{file}.pkl\"\n",
    "info_metrics_path = f\"{file}-info-{byte_count}Bytes.json\"\n",
    "\n",
    "info_metrics = json.load(open(info_metrics_path))\n",
    "\n",
    "# os.chdir('../XtractPredictor/')\n",
    "classifier = pickle.load(open(classifier_path, \"rb\"))\n",
    "# os.chdir('../xtract-research-notebooks/')\n",
    "\n",
    "for key in info_metrics.keys():\n",
    "    print(key)\n",
    "    print(f'\\t{info_metrics[key]}')\n",
    "\n",
    "precision = info_metrics['Model precision']\n",
    "recall = info_metrics['Model recall']\n",
    "print(f'F1-Score\\n\\t{2*precision*recall/(precision+recall)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
